zlab = "Tau",surface.alpha = 0.4))
with(a,scatter3d(x = boundary, y = cp, z = tau,group = fthetaA,fit = "smooth",xlab = "Decision Boundary", ylab = "Empirical Type 2 error",
zlab = "Tau",surface.alpha = 0.4))
library(MCMCpack)
library(actuar)
library(msm)
library(foreach)
library(doParallel)
library(invgamma)
n1 = rep(10,8)
y1_bar = rep(1,8)
x1_bar = rep(c(1,1.5,2,2.5),2)
z1_bar = rep(c(0,0.5,1,1.5),2)
s2 = c(rep(2,4),rep(2.5,4))
cp = rep(0,8)
cp.data = as.data.frame(cbind(n1,y1_bar,x1_bar,z1_bar,s2,cp))
#conditional power become a function of only n1 and n2
fz = function(z1_bar,s2,n1){
z1 = (z1_bar/s2)*sqrt(n1/2)
return(z1)
}
fcp = function(z1,n1,sigma2 = 2.25){
cp = pnorm(qnorm(alpha/2)*sqrt((n1+n1)/n1)+z1*sqrt(n1/n1)+z1*sqrt(n1/(2*sigma2)))
return(cp)
}
cp.data$z1 = mapply(fz,cp.data$z1_bar,cp.data$s2,cp.data$n1)
cp.data$cp = mapply(fcp,cp.data$z1,cp.data$n1)
#conditional power:
alpha = 0.05
n = 20
pi = 0.5
n1 = n*pi
n2 = n-n1
# simulate interim results:
# p(sigma2), use mean and sd to define standard deviation, find the sigma2
mean.sigma2 = 2.25
sd.sigma2 = 2
alpha0 = 2 + (mean.sigma2/sd.sigma2)^2
beta0 = mean.sigma2*(alpha0-1)
sigma2 = rinvgamma(1,shape = alpha0, rate = 1/beta0, scale = beta0)
# p(theta|sigma2), find the theta_A
mu0.x = 2
mu0.y = 1
theta0 = mu0.x - mu0.y
n0 = 1
z1_bar = rnorm(1,mean = theta0,sd = sqrt(2*sigma2)/(n0*n1))
x1_bar = rnorm(1,mean = mu0.x, sd = sqrt(sigma2/(n0*n1)))
y1_bar = x1_bar - z1_bar
s2 = (rchisq(1,df = 2*n1-2)*sigma2)/(2*n1-2)
z1 = (z1_bar/s2)*sqrt(n1/2)
# need to specify z1, theta_A and sigma2_A
# empirical trend theta_A = z1
theta_A = z1
sigma2_A = sigma2
CP = pnorm(qnorm(alpha/2)*sqrt((n1+n2)/n2)+z1*sqrt(n1/n2)+theta_A*sqrt(n2/(2*sigma2_A)))
#choose the mean of sigma2
sigma2 = 2.25
z1_bar = rnorm(1000,mean = theta0,sd = sqrt(2*sigma2)/(n0*n1))
n1 = rep(10,8)
y1_bar = rep(1,8)
x1_bar = rep(c(1,1.5,2,2.5),2)
z1_bar = rep(c(0,0.5,1,1.5),2)
s2 = c(rep(2,4),rep(2.5,4))
cp = rep(0,8)
cp.data = as.data.frame(cbind(n1,y1_bar,x1_bar,z1_bar,s2,cp))
#conditional power become a function of only n1 and n2
fz = function(z1_bar,s2,n1){
z1 = (z1_bar/s2)*sqrt(n1/2)
return(z1)
}
fcp = function(z1,n1,sigma2 = 2.25){
cp = pnorm(qnorm(alpha/2)*sqrt((n1+n1)/n1)+z1*sqrt(n1/n1)+z1*sqrt(n1/(2*sigma2)))
return(cp)
}
cp.data$z1 = mapply(fz,cp.data$z1_bar,cp.data$s2,cp.data$n1)
cp.data$cp = mapply(fcp,cp.data$z1,cp.data$n1)
cp.data$z1 = NULL
cp.names = c("n1=n2","y1_bar","x1_bar","z1_bar","sample variance","conditional power")
names(cp.data) = cp.names
print(cp.data)
# predictive power:
# sample size:
n = 20
pi = 0.5
n1 = n*pi
n2 = n-n1
# pdf for posterior sigma2, need to specify x1_bar, y1_bar and s2
# set values for them, without being mean?
z1_bar = 1.5
y1_bar = 1
x1_bar = 0.5
s2 = 2.5
z1 = (z1_bar/s2)*sqrt(n1/2)
# required parameters for p(sigma2)
mean.sigma2 = 2.25
sd.sigma2 = 2
alpha0 = 2 + (mean.sigma2/sd.sigma2)^2
beta0 = mean.sigma2*(alpha0-1)
# p(sigma2)
igpdf = function(x){dinvgamma(x,shape = alpha0+n1,
scale = beta0+(n1-1)*s2+
n0*n1*(((x1_bar-mu0.x)^2)+
((y1_bar-mu0.y )^2))/(2*(n0+n1)))}
# required parameters for p(theta|sigma2)
mu0.x = 2
mu0.y = 1
theta0 = mu0.x - mu0.y
n0 = 1
# p(theta) has sigma value in it.
theta1 = (n0*theta0 + n1*z1_bar)/(n0+n1)
npdf = function(x){dnorm(x,mean = theta1,sd = sqrt(2*sigma/(n0+n1)))}
PP = integrate(function(sig){
sapply(sig,function(sig){
integrate(function(thet){
npdf = function(x){dnorm(x,mean = theta1,sd = sqrt(2*sig/(n0+n1)))}
pnorm(qnorm(alpha/2)*sqrt((n1+n2)/n2)+z1*sqrt(n1/n2)+thet*(n2/(2*sig)))*
npdf(thet)*
igpdf(sig)},-Inf,Inf)}$value)},0,Inf)$value
print(PP)
#conditional expected power
CEP = integrate(function(sig){
sapply(sig,function(sig){
integrate(function(thet){
npdf = function(x){dtnorm(x,mean = theta1,sd = sqrt(2*sig/(n0+n1)),0,Inf)}
pnorm(qnorm(alpha/2)*sqrt((n1+n2)/n2)+z1*sqrt(n1/n2)+thet*(n2/(2*sig)))*
npdf(thet)*
igpdf(sig)},0,Inf)}$value)},0,Inf)$value
print(CEP)
#predictive power in a different way:
#required parameters:
alpha1 = alpha0+n1
beta1 = beta0+(n1 - 1)*s2+n0*n1*(((x1_bar-mu0.x)^2)+
((y1_bar-mu0.y )^2))/(2*(n0+n1))
#these parameters seem to be very large.
theta1 = (n0*theta0 + n1*z1_bar)/(n0+n1)
S = 1000
sigma2.post.vec = seq(qinvgamma(.001, shape=alpha1, rate=1/beta1, scale=beta1),
qinvgamma(.999, shape=alpha1, rate=1/beta1, scale=beta1),
length=S)
dsigma2.post = (sigma2.post.vec[S]-sigma2.post.vec[1])/(S-1)
TH = 1000
a = data.frame(sigma2 = rep(sigma2.post.vec, each=TH), dsigma2.post)
#not using truncated normal for PP
minoftheta = qnorm(.001, mean=theta1, sd=sqrt(2*sigma2.post.vec/(n1+n0)))
maxoftheta = qnorm(.999, mean=theta1, sd=sqrt(2*sigma2.post.vec/(n1+n0)))
a$theta = foreach(i = minoftheta, ii=maxoftheta, .combine = "c") %do% seq(i,ii,length=TH)
a$dtheta.post = rep((maxoftheta-minoftheta)/(TH-1), each=TH)
a$Delta = a$theta/sqrt(a$sigma2)
# p(sigma2)
a$post.sigma2 = dinvgamma(a$sigma2,shape=alpha1,rate=1/beta1,scale=beta1)
# p(theta | sigma2)
a$post.theta = dnorm(a$theta,mean=theta1,sd=sqrt(2*sigma2.post.vec/(n1+n0)))
# p(theta, sigma2)
a$post.thetasigma2 = a$post.sigma2 * a$post.theta
# Posterior conditional power
Inside0 = qnorm(alpha/2)*sqrt((n1+n2)/n2)+z1*sqrt(n1/n2)+ a$Delta*(n2/sqrt(2))
PCP = pnorm(Inside0)
PP = (sum(PCP * a$post.thetasigma2 * a$dtheta.post))*dsigma2.post
#Conditional expected power
#required parameters:
alpha1 = alpha0+n1
beta1 = beta0+(n1 - 1)*s2+n0*n1*(((x1_bar-mu0.x)^2)+
((y1_bar-mu0.y )^2))/(2*(n0+n1))
#these parameters seem to be very large.
theta1 = (n0*theta0 + n1*z1_bar)/(n0+n1)
S = 1000
sigma2.post.vec = seq(qinvgamma(.001, shape=alpha1, rate=1/beta1, scale=beta1),
qinvgamma(.999, shape=alpha1, rate=1/beta1, scale=beta1),
length=S)
dsigma2.post = (sigma2.post.vec[S]-sigma2.post.vec[1])/(S-1)
TH = 1000
a = data.frame(sigma2 = rep(sigma2.post.vec, each=TH), dsigma2.post)
#using truncated normal for CEP
minoftheta = qtnorm(.001, mean=theta1, sd=sqrt(2*sigma2.post.vec/(n1+n0)),0,Inf)
maxoftheta = qtnorm(.999, mean=theta1, sd=sqrt(2*sigma2.post.vec/(n1+n0)),0,Inf)
a$theta = foreach(i = minoftheta, ii=maxoftheta, .combine = "c") %do% seq(i,ii,length=TH)
a$dtheta.post = rep((maxoftheta-minoftheta)/(TH-1), each=TH)
a$Delta = a$theta/sqrt(a$sigma2)
# p(sigma2)
a$post.sigma2 = dinvgamma(a$sigma2,shape=alpha1,rate=1/beta1,scale=beta1)
# p(theta | sigma2)
a$post.theta = dtnorm(a$theta,mean=theta1,sd=sqrt(2*sigma2.post.vec/(n1+n0)),0,Inf)
# p(theta, sigma2)
a$post.thetasigma2 = a$post.sigma2 * a$post.theta
# Posterior conditional power
Inside0 = qnorm(alpha/2)*sqrt((n1+n2)/n2)+z1*sqrt(n1/n2)+ a$Delta*(n2/sqrt(2))
PCP = pnorm(Inside0)
CEP = (sum(PCP * a$post.thetasigma2 * a$dtheta.post))*dsigma2.post
print(PP)
print(CEP)
#at the beginning stage
#Professor's method
alpha = 0.05
# sample size:
n = 20
p = 0.5
n1 = n*p
n2 = n-n1
#p(sigma2)
#mean.sigma2 = 2.25
#sd.sigma2 = 2
alpha0 = 3
beta0 = 5
#p(theta|sigma2)
mu0.x = 2
mu0.y = 1
theta0 = 1
n0 = 1
S = 10000
sigma2.prior.vec = seq(qinvgamma(.0001, shape=alpha0, rate=1/beta0, scale=beta0),
qinvgamma(.9999, shape=alpha0, rate=1/beta0, scale=beta0),
length=S)
dsigma2.prior = (sigma2.prior.vec[S]-sigma2.prior.vec[1])/(S-1)
TH = 10000
a = data.frame(sigma2 = rep(sigma2.prior.vec, each=TH), dsigma2.prior)
#not using truncated normal for PP
minoftheta = qnorm(.001, mean=theta0, sd=sqrt((2*sigma2.prior.vec)/n0))
maxoftheta = qnorm(.999, mean=theta0, sd=sqrt((2*sigma2.prior.vec)/n0))
a$theta = foreach(i = minoftheta, ii=maxoftheta, .combine = "c") %do% seq(i,ii,length=TH)
a$dtheta.prior = rep((maxoftheta-minoftheta)/(TH-1), each=TH)
a$Delta = a$theta/sqrt(a$sigma2)
# p(sigma2)
a$prior.sigma2 = dinvgamma(a$sigma2,shape=alpha0,rate=1/beta0,scale=beta0)
# p(theta | sigma2)
a$prior.theta = dnorm(a$theta,mean=theta0,sd=sqrt((2*sigma2.prior.vec)/n0))
# p(theta, sigma2)
a$prior.thetasigma2 = a$prior.sigma2 * a$prior.theta
# beginning conditional power
z.alpha = qnorm(alpha/2)
Inside0 = z.alpha + (a$Delta)*(sqrt(n/2))
PCP = pnorm(Inside0)
PP = (sum(PCP * a$prior.thetasigma2 * a$dtheta.prior))*dsigma2.prior
print(PP)
#my way
igpdf = function(x){
dinvgamma(x,3,5)
}
PP = integrate(function(sig2){
sapply(sig2,function(sig2){
integrate(function(thet){
npdf = function(q){dnorm(q, 1,sd = sqrt(2*sig2))}
pnorm(z.alpha+(thet/sqrt(sig2))*sqrt(n/2))*
npdf(thet)*
igpdf(sig2)
},-Inf,Inf)$value})
},0,Inf)
print(PP)
#evaluate CDF
ecdf = function(u){
exp((-u^2)/2)
}
cdff = function(x){
(1/sqrt(2*pi))*integrate(ecdf, -Inf, x)$value
}
integral <- function(z.alpha,n,ptheta,psigma){
integrate(f = function(sigmavec) sapply (sigmavec, function(sigma){
integrate(f = function(theta){
pnorm(z.alpha+(theta/sqrt(sigma))*sqrt(n/2))*ptheta(theta)*psigma(sigma)
},-Inf,Inf)
}),0,Inf)
}
integral(z.alpha, 20, dnorm, dinvgamma)
cd
getwd()
install.packages('usethis')
library('usethis')
plot(x,exp(x))
x = seq(1,10,by=0.01)
plot(x,exp(x))
exp(10)
1+sqrt(3)/2
sqrt(3)/2
0.5+sqrt(12)/4
library(devtools)
document()
1/1/exp(1)
source("slantlets.r")
FirstKEncode <- function(y, fidelity=.99) {
n <- length(y)
# Calculate the coefficients of y with respect to the slantlet basis.
B <- sltmtx(log2(n))
z <- t(B) %*% y
# "coeffs" should be a vector of coefficients of y with respect to
# slantlet basis vectors (in the order given by the "sltmtx" function).
approx <- rep(0, n)
s <- sum((y-mean(y))^2)
for(i in 1:n) {
approx <- approx + z[i] * B[, i]
fid <- 1 - sum((y-approx)^2)/s # "fidelity" of approximation
if (fid > fidelity){
n = i
break
}
}
# turn approx back to coordinates
coeffs = t(B) %*% approx
#return the n needed to achieve fidelity
return(c(n, coeffs))
}
FirstKDecode <- function(x) {
# Use "sltmtx" to construct the slantlet basis for the given n,
B <- sltmtx(log2(length(x)))
x <- as.matrix(x)
decode <- B %*% x
return(decode)
}
n <- 16
lake <- LakeHuron[1:n]
k = FirstKEncode(lake)
m = k[2:length(k)]
plot(m)
plot(x=seq(1,n),y=m,type='l')
lines(x=seq(1,n),y=lake)
plot(x=seq(1,n),y=m,type='l')
lines(x=seq(1,n),y=lake)
plot(x=seq(1,n),y=m,type='l')
lines(x=seq(1,n),y=lake,col='red')
lake
k
m
FirstKEncode <- function(y, fidelity=.99) {
n <- length(y)
# Calculate the coefficients of y with respect to the slantlet basis.
B <- sltmtx(log2(n))
z <- t(B) %*% y
# "coeffs" should be a vector of coefficients of y with respect to
# slantlet basis vectors (in the order given by the "sltmtx" function).
approx <- rep(0, n)
s <- sum((y-mean(y))^2)
for(i in 1:n) {
approx <- approx + z[i] * B[, i]
fid <- 1 - sum((y-approx)^2)/s # "fidelity" of approximation
if (fid > fidelity){
n = i
break
}
}
# turn approx back to coordinates
coeffs = t(B) %*% approx
#return the n needed to achieve fidelity
return(c(n, coeffs))
}
k = FirstKEncode(lake)
k
FirstKEncode <- function(y, fidelity=.99) {
n <- length(y)
# Calculate the coefficients of y with respect to the slantlet basis.
B <- sltmtx(log2(n))
z <- t(B) %*% y
# "coeffs" should be a vector of coefficients of y with respect to
# slantlet basis vectors (in the order given by the "sltmtx" function).
approx <- rep(0, n)
s <- sum((y-mean(y))^2)
for(i in 1:n) {
approx <- approx + z[i] * B[, i]
fid <- 1 - sum((y-approx)^2)/s # "fidelity" of approximation
if (fid > fidelity){
n = i
break
}
}
#return the n needed to achieve fidelity
return(c(n, approx))
}
k = FirstKEncode(lake)
k
B <- sltmtx(log2(n))
t(B)*%*k[2:17]
t(B)%*%k[2:17]
k[2:17]
B%*%k[2:17]
B
B
B <- sltmtx(log2(n)) #function that gives you an ON Basis
B
0.25**2
0.25**2*16
k = FirstKEncode(lake)
k
m = k[2:length(k)]
m
lake
t(B)%*%lake
m = FirstKDecode(m)
m
plot(x=seq(1,n),y=m,type='l')
lines(x=seq(1,n),y=lake,col='red')
plot(x=seq(1,n),y=m,type='l')
lines(x=seq(1,n),y=lake,col='red')
m = k[2:length(k)]
as.matrix(m)
FirstKEncode <- function(y, fidelity=.99) {
n <- length(y)
# Calculate the coefficients of y with respect to the slantlet basis.
B <- sltmtx(log2(n))
z <- t(B) %*% y
# "coeffs" should be a vector of coefficients of y with respect to
# slantlet basis vectors (in the order given by the "sltmtx" function).
approx <- rep(0, n)
s <- sum((y-mean(y))^2)
for(i in 1:n) {
approx <- approx + z[i] * B[, i]
fid <- 1 - sum((y-approx)^2)/s # "fidelity" of approximation
if (fid > fidelity){
n = i
break
}
}
# turn approx back to coordinates
coeffs = t(B) %*% approx
#return the n needed to achieve fidelity
return(c(n, coeffs))
}
k = FirstKEncode(lake)
m = k[2:length(k)]
m = FirstKDecode(m)
plot(x=seq(1,n),y=m,type='l')
lines(x=seq(1,n),y=lake,col='red')
source("slantlets.r")
FirstKEncode <- function(y, fidelity=.99) {
n <- length(y)
# Calculate the coefficients of y with respect to the slantlet basis.
B <- sltmtx(log2(n))
z <- t(B) %*% y
# "coeffs" should be a vector of coefficients of y with respect to
# slantlet basis vectors (in the order given by the "sltmtx" function).
approx <- rep(0, n)
s <- sum((y-mean(y))^2)
for(i in 1:n) {
approx <- approx + z[i] * B[, i]
fid <- 1 - sum((y-approx)^2)/s # "fidelity" of approximation
if (fid > fidelity){
n = i
break
}
}
# turn approx back to coordinates
coeffs = t(B) %*% approx
#return the n needed to achieve fidelity
return(c(n, coeffs))
}
FirstKDecode <- function(x) {
# Use "sltmtx" to construct the slantlet basis for the given n,
B <- sltmtx(log2(length(x)))
x <- as.matrix(x)
decode <- B %*% x
return(decode)
}
BestKEncode <- function(y, fidelity=.99) {
n <- length(y)
# Calculate the coefficients of y with respect to the slantlet basis.
B <- sltmtx(log2(n))
z <- t(B) %*% y
# "indices" should be a vector containing the indices of the slantlet basis
# vectors that will be used for the approximation, ordered by importance.
indices <- order(abs(z), decreasing=TRUE)
# "coeffs" should be a vector of the coefficients of y with
# respect to those specified basis vectors.
# (Include just enough basis vectors to achieve the specified fidelity.)
approx <- rep(0, n)
s <- sum((y-mean(y))^2)
for(i in 1:n) {
approx <- approx + z[indices[i]] * B[, indices[i]]
fid <- 1 - sum((y-approx)^2)/s
if (fid > fidelity){
n = i
break
}
coeffs = t(B) %*% approx
}
return(c(n, indices, coeffs))
}
BestKDecode <- function(x) {
# Use "sltmtx" to construct the slantlet basis for the given n,
B <- sltmtx(log2(length(x)))
x <- as.matrix(x)
decode <- B %*% x
return(decode)
}
```{r}
n <- 1024
y.raw <- EuStockMarkets[1:n, 1]
plot(y.raw, type="l", main="DAX", ylab="closing price", xlab="day")
y.fk <- FirstKEncode(y.raw)
y.bk <- BestKEncode(y.raw)
print(y.fk[1]/n)
print(y.bk[1]/n)
y.fk[1:n]
kdecode = FirstKDecode(y.fk[1:n])
bdecode = BestKDecode(y.bk[1:n])
par(mfrow=c(1, 2))
plot(y.raw, type="l", main="Original and First-K approximation")
# lines( ... )
lines(x=seq(1,length(kdecode),by=1),y = kdecode,col='red')
plot(y.raw, type="l", main="Original and Best-K approximation")
# lines( ... )
lines(x=seq(1,length(bdecode),by=1),y = kdecode,col='red')
y.fk
y.fk[1]
kdecode = FirstKDecode(y.fk[2:n])
kdecode = FirstKDecode(y.fk[2:n+1])
y.fk[2:n+1]
kdecode = FirstKDecode(y.fk[1:n+1])
bdecode = BestKDecode(y.bk[1:n+1])
par(mfrow=c(1, 2))
plot(y.raw, type="l", main="Original and First-K approximation")
# lines( ... )
lines(x=seq(1,length(kdecode),by=1),y = kdecode,col='red')
plot(y.raw, type="l", main="Original and Best-K approximation")
# lines( ... )
lines(x=seq(1,length(bdecode),by=1),y = kdecode,col='red')
setwd('/Users/bo/Desktop/2020 fall/Computational/homework-1/bis557')
